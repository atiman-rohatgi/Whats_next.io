{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9146b659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.12/site-packages (5.0.0)\n",
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/lib/python3.12/site-packages (1.11.0)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: jupyterlab in /opt/anaconda3/lib/python3.12/site-packages (4.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.53.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (0.33.2)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab) (0.27.0)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab) (6.28.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab) (2.2.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab) (0.2.3)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab) (75.1.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab) (6.4.1)\n",
      "Requirement already satisfied: traitlets in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab) (4.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab) (1.0.2)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.14.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: appnope in /opt/anaconda3/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.3)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/anaconda3/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/anaconda3/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (8.27.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/anaconda3/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (8.6.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /opt/anaconda3/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/anaconda3/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (25.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2>=3.0.3->jupyterlab) (2.1.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-core->jupyterlab) (3.10.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (21.3.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.4)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.14.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/anaconda3/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.8.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.10.6)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/anaconda3/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: ptyprocess in /opt/anaconda3/lib/python3.12/site-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.12/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.3)\n",
      "Requirement already satisfied: fqdn in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.1)\n",
      "Requirement already satisfied: uri-template in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.11.1)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.5)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.5)\n",
      "Requirement already satisfied: executing in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/anaconda3/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.2.3)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install pandas numpy scikit-learn sentence-transformers faiss-cpu joblib jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6fba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.sparse import hstack\n",
    "import faiss\n",
    "import joblib\n",
    "import ast\n",
    "import re\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ebcc54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games = pd.read_csv('df_games.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8398b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings matrix loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the embeddings matrix from the .npy file\n",
    "embeddings_matrix = np.load(\"embeddings_matrix.npy\")\n",
    "print(\"Embeddings matrix loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ed4fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the search function\n",
    "def search(dataframe, column_name, search_string):\n",
    "    return dataframe[dataframe[column_name].str.contains(search_string, case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f19fcafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword_soup cleaning\n",
    "df_games['keyword_soup'] = df_games['keyword_soup'].fillna('').astype(str)\n",
    "\n",
    "import re\n",
    "# Replace multiple spaces with a single space and strip leading/trailing spaces\n",
    "df_games['name'] = df_games['name'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a01ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games.to_csv(\"df_games.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2f06ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created final, production-ready feature vectors.\n",
      "Final vector shape: (88886, 300)\n"
     ]
    }
   ],
   "source": [
    "#vector creation (final_production_vectors.npy)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "\n",
    "# --- 1. Define Your Final, Tuned Weights ---\n",
    "# These weights prioritize content and publisher identity.\n",
    "keyword_weight = 2.0\n",
    "publisher_weight = 2.5\n",
    "semantic_weight = 2.5\n",
    "numerical_weight = 1.0\n",
    "\n",
    "# --- 3. Build a Professional Preprocessing Pipeline ---\n",
    "\n",
    "# Define the columns for each transformer\n",
    "numerical_features = ['game_age', 'reviews_per_year', 'quality_score']\n",
    "keyword_features = 'keyword_soup'\n",
    "publisher_features = 'publisher_cleaned'\n",
    "\n",
    "# Create the master preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('keywords', TfidfVectorizer(max_features=1000, stop_words='english', ngram_range=(1,2), min_df=5), keyword_features),\n",
    "        ('publisher', TfidfVectorizer(max_features=500), publisher_features) # Limit publisher features\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'num': numerical_weight,\n",
    "        'keywords': keyword_weight,\n",
    "        'publisher': publisher_weight\n",
    "    })\n",
    "\n",
    "# --- 4. Process Data and Combine with Semantics ---\n",
    "\n",
    "# Apply the entire pipeline to get weighted numerical, keyword, and publisher features\n",
    "processed_features = preprocessor.fit_transform(df_games)\n",
    "\n",
    "# Apply weight to the semantic vectors\n",
    "weighted_semantics = embeddings_matrix * semantic_weight\n",
    "\n",
    "# Combine all features into one matrix\n",
    "combined_weighted_vectors = hstack([\n",
    "    processed_features,\n",
    "    csr_matrix(weighted_semantics)\n",
    "]).astype('float32')\n",
    "\n",
    "# --- 5. Dimensionality Reduction for Accuracy ---\n",
    "\n",
    "# Reduce the combined features to their most important 300 signals\n",
    "svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "reduced_vectors = svd.fit_transform(combined_weighted_vectors)\n",
    "\n",
    "# --- 6. Normalize and Finalize ---\n",
    "\n",
    "# Normalize the final vectors for accurate similarity search\n",
    "final_vectors_normalized = normalize(reduced_vectors, norm='l2', axis=1)\n",
    "\n",
    "# Convert to the final format for Faiss\n",
    "final_vectors = final_vectors_normalized.astype('float32')\n",
    "\n",
    "print(\"Successfully created final, production-ready feature vectors.\")\n",
    "print(\"Final vector shape:\", final_vectors.shape)\n",
    "\n",
    "# Save the final vectors for your engine\n",
    "np.save(\"final_production_vectors.npy\", final_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2e8eb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of vectors: (88886, 300)\n",
      "Shape of query vector: (1, 300)\n",
      "--- Recommendations for a fan of Counter Strike 2, Grand Theft Auto V, Red Dead Redemption 2 ---\n",
      "\n",
      "Rate the following recommendations (1-10):\n",
      "\n",
      "Current recommendations above threshold (8): ['Counter Strike 2', 'Grand Theft Auto V', 'Call of Duty', 'Marvel Rivals']\n",
      "Shape of query vector: (1, 300)\n",
      "--- Recommendations for a fan of Counter Strike 2, Grand Theft Auto V, Red Dead Redemption 2, Call of Duty, Marvel Rivals ---\n",
      "\n",
      "Rate the following recommendations (1-10):\n",
      "\n",
      "Current recommendations above threshold (8): ['Counter Strike 2', 'Grand Theft Auto V', 'Dying Light', 'HELLDIVERS 2']\n",
      "Shape of query vector: (1, 300)\n",
      "--- Recommendations for a fan of Counter Strike 2, Grand Theft Auto V, Red Dead Redemption 2, Dying Light, HELLDIVERS 2 ---\n",
      "\n",
      "Rate the following recommendations (1-10):\n",
      "\n",
      "Current recommendations above threshold (8): ['Counter Strike 2', 'Grand Theft Auto V', 'Marvel Rivals']\n",
      "Shape of query vector: (1, 300)\n",
      "--- Recommendations for a fan of Counter Strike 2, Grand Theft Auto V, Red Dead Redemption 2, Marvel Rivals ---\n",
      "\n",
      "Rate the following recommendations (1-10):\n",
      "\n",
      "Current recommendations above threshold (8): ['Counter Strike 2', 'Grand Theft Auto V', 'Call of Duty', 'Dying Light']\n",
      "Shape of query vector: (1, 300)\n",
      "--- Recommendations for a fan of Counter Strike 2, Grand Theft Auto V, Red Dead Redemption 2, Call of Duty, Dying Light ---\n",
      "\n",
      "Rate the following recommendations (1-10):\n",
      "\n",
      "Current recommendations above threshold (8): ['Counter Strike 2', 'Grand Theft Auto V', \"Baldur's Gate 3\", 'HELLDIVERS 2', 'Sons Of The Forest']\n",
      "\n",
      "Final recommendations:\n",
      "1. Counter Strike 2\n",
      "2. Grand Theft Auto V\n",
      "3. Baldur's Gate 3\n",
      "4. HELLDIVERS 2\n",
      "5. Sons Of The Forest\n",
      "Shape of vectors: (88886, 300)\n",
      "Shape of query vector: (1, 300)\n",
      "--- Recommendations for a fan of Counter Strike 2, Grand Theft Auto V, Red Dead Redemption 2 ---\n",
      "1. My Summer Car\n",
      "2. Sons Of The Forest\n",
      "3. Ready or Not\n",
      "4. Call of Duty\n",
      "5. THE FINALS\n"
     ]
    }
   ],
   "source": [
    "#engine 3 (the main engine file) (using IVFFlatL2)\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#engine 3 (interactive recommendation engine)\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Load all necessary components ---\n",
    "df_games = pd.read_csv(\"df_games.csv\")  # Or your full cleaned dataset CSV\n",
    "vectors = np.load(\"final_production_vectors.npy\")  # Load the improved hybrid vectors\n",
    "\n",
    "# Verify the dimensions of the vectors\n",
    "print(f\"Shape of vectors: {vectors.shape}\")\n",
    "\n",
    "# Rebuild the Faiss index with the correct dimensions\n",
    "d = vectors.shape[1]  # Number of dimensions\n",
    "index = faiss.IndexFlatL2(d)  # L2 distance metric\n",
    "index.add(vectors)  # Add the vectors to the index\n",
    "\n",
    "title_to_index = pd.Series(df_games.index, index=df_games['name'])\n",
    "\n",
    "def get_profile_recommendations(game_titles, ratings, k=6):\n",
    "    \"\"\"\n",
    "    Finds and prints recommendations based on a weighted average profile of input games.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the number of games and ratings match\n",
    "        if len(game_titles) != len(ratings):\n",
    "            print(\"Error: The number of games and ratings must be the same.\")\n",
    "            return []\n",
    "\n",
    "        # 1. Check if all titles exist in the dataset\n",
    "        missing_titles = [title for title in game_titles if title not in title_to_index.index]\n",
    "        if missing_titles:\n",
    "            print(f\"Error: The following games were not found in the dataset: {', '.join(missing_titles)}\")\n",
    "            return []\n",
    "\n",
    "        # 2. Get the vectors for all input games\n",
    "        input_vectors = [vectors[title_to_index[title]] for title in game_titles]\n",
    "\n",
    "        # 3. Calculate the WEIGHTED average vector to create the \"taste profile\"\n",
    "        query_vector = np.average(input_vectors, axis=0, weights=ratings).reshape(1, -1).astype('float32')\n",
    "\n",
    "        # Verify the dimensions of the query vector\n",
    "        print(f\"Shape of query vector: {query_vector.shape}\")\n",
    "\n",
    "        # Set nprobe for the loaded index\n",
    "        index.nprobe = 10 \n",
    "\n",
    "        # 4. Search the Faiss index\n",
    "        distances, indices = index.search(query_vector, k)\n",
    "\n",
    "        print(f\"--- Recommendations for a fan of {', '.join(game_titles)} ---\")\n",
    "        \n",
    "        # 5. Collect the results, filtering out the input games\n",
    "        recs = []\n",
    "        for i in range(k):\n",
    "            rec_title = df_games.iloc[indices[0][i]]['name']\n",
    "            if rec_title not in game_titles:\n",
    "                recs.append(rec_title)\n",
    "\n",
    "        return recs\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Game {e} not found in the dataset.\")\n",
    "        return []\n",
    "\n",
    "def interactive_recommendation_engine(initial_games, initial_ratings, threshold=8, max_recs=5):\n",
    "    \"\"\"\n",
    "    Runs an interactive recommendation engine that refines recommendations based on user ratings.\n",
    "    \n",
    "    Args:\n",
    "        initial_games (list): List of initial game titles.\n",
    "        initial_ratings (list): List of ratings corresponding to the initial games.\n",
    "        threshold (int): Minimum rating threshold for recommendations.\n",
    "        max_recs (int): Maximum number of recommendations to finalize.\n",
    "    \"\"\"\n",
    "    current_games = initial_games\n",
    "    current_ratings = initial_ratings\n",
    "    final_recommendations = []\n",
    "\n",
    "    while len(final_recommendations) < max_recs:\n",
    "        # Run the recommendation function\n",
    "        recommendations = get_profile_recommendations(current_games, current_ratings, k=5)\n",
    "        if not recommendations:\n",
    "            print(\"No recommendations found. Exiting.\")\n",
    "            break\n",
    "\n",
    "        # Ask the user to rate the recommendations\n",
    "        print(\"\\nRate the following recommendations (1-10):\")\n",
    "        new_games = []\n",
    "        new_ratings = []\n",
    "\n",
    "        for rec_game in recommendations:\n",
    "            try:\n",
    "                rating = int(input(f\"Enter your rating for '{rec_game}' (1-10): \"))\n",
    "                if rating >= threshold:\n",
    "                    new_games.append(rec_game)\n",
    "                    new_ratings.append(rating)\n",
    "            except ValueError:\n",
    "                print(\"Invalid rating. Skipping this game.\")\n",
    "\n",
    "        # Update the list of games and ratings\n",
    "        current_games = initial_games + new_games\n",
    "        current_ratings = initial_ratings + new_ratings\n",
    "\n",
    "        # Filter recommendations above the threshold\n",
    "        final_recommendations = [game for game, rating in zip(current_games, current_ratings) if rating >= threshold]\n",
    "\n",
    "        print(f\"\\nCurrent recommendations above threshold ({threshold}): {final_recommendations}\")\n",
    "\n",
    "        # Check if the user wants to stop\n",
    "        stop = input(\"Press 'q' to stop or Enter to continue: \").strip().lower()\n",
    "        if stop == 'q':\n",
    "            break\n",
    "\n",
    "    print(\"\\nFinal recommendations:\")\n",
    "    for i, game in enumerate(final_recommendations[:max_recs], start=1):\n",
    "        print(f\"{i}. {game}\")\n",
    "\n",
    "# Example usage\n",
    "test_games = [\"Counter Strike 2\", \"Grand Theft Auto V\", \"Red Dead Redemption 2\"]\n",
    "test_ratings = [10, 10, 5]\n",
    "interactive_recommendation_engine(test_games, test_ratings)\n",
    "# --- Load all necessary components ---\n",
    "df_games = pd.read_csv(\"df_games.csv\")  # Or your full cleaned dataset CSV\n",
    "vectors = np.load(\"final_production_vectors.npy\")  # Load the improved hybrid vectors\n",
    "\n",
    "# Verify the dimensions of the vectors\n",
    "print(f\"Shape of vectors: {vectors.shape}\")\n",
    "\n",
    "# Rebuild the Faiss index with the correct dimensions\n",
    "d = vectors.shape[1]  # Number of dimensions\n",
    "index = faiss.IndexFlatL2(d)  # L2 distance metric\n",
    "index.add(vectors)  # Add the vectors to the index\n",
    "\n",
    "title_to_index = pd.Series(df_games.index, index=df_games['name'])\n",
    "\n",
    "def get_profile_recommendations(game_titles, ratings, k=6): # Added 'ratings' parameter\n",
    "    \"\"\"\n",
    "    Finds and prints recommendations based on a weighted average profile of input games.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the number of games and ratings match\n",
    "        if len(game_titles) != len(ratings):\n",
    "            print(\"Error: The number of games and ratings must be the same.\")\n",
    "            return\n",
    "\n",
    "        # 1. Check if all titles exist in the dataset\n",
    "        missing_titles = [title for title in game_titles if title not in title_to_index.index]\n",
    "        if missing_titles:\n",
    "            print(f\"Error: The following games were not found in the dataset: {', '.join(missing_titles)}\")\n",
    "            return\n",
    "        \n",
    "        # 2. Get the vectors for all input games\n",
    "        input_vectors = [vectors[title_to_index[title]] for title in game_titles]\n",
    "        \n",
    "        # 3. Calculate the WEIGHTED average vector to create the \"taste profile\"\n",
    "        query_vector = np.average(input_vectors, axis=0, weights=ratings).reshape(1, -1).astype('float32')\n",
    "        \n",
    "        # Verify the dimensions of the query vector\n",
    "        print(f\"Shape of query vector: {query_vector.shape}\")\n",
    "\n",
    "        # New line: Increase the search accuracy\n",
    "        index.nprobe = 10 \n",
    "        \n",
    "        # 4. Search the Faiss index\n",
    "        distances, indices = index.search(query_vector, k)\n",
    "        \n",
    "        print(f\"--- Recommendations for a fan of {', '.join(game_titles)} ---\")\n",
    "        \n",
    "        # 5. Print the results, filtering out the input games\n",
    "        recs = []\n",
    "        for i in range(k):\n",
    "            rec_title = df_games.iloc[indices[0][i]]['name']\n",
    "            if rec_title not in game_titles:\n",
    "                recs.append(rec_title)\n",
    "        \n",
    "        for i, rec in enumerate(recs):\n",
    "            print(f\"{i+1}. {rec}\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Game {e} not found in the dataset.\")\n",
    "\n",
    "# --- Now, test with both games! ---\n",
    "test_games = [\"Counter Strike 2\", \"Grand Theft Auto V\", \"Red Dead Redemption 2\"]\n",
    "# Add a list of ratings (out of 10) to correspond to the games\n",
    "test_ratings = [1, 10, 10]\n",
    "# Call the function with the new ratings parameter\n",
    "get_profile_recommendations(test_games, test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7b515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a recusive function to test the engine with different games and ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef160bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search(df_games, 'name', \"assassin's creed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16179e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding vectors: Adding 4 dimensions to match Faiss index dimensionality.\n",
      "Adjusted shape of vectors: (88886, 304)\n",
      "Successfully loaded production index.\n",
      "Shape of vectors: (88886, 304)\n",
      "Faiss index dimensionality: 304\n",
      "Shape of query vector: (1, 304)\n",
      "--- Recommendations for a fan of Counter Strike 2, Grand Theft Auto V, Red Dead Redemption 2 ---\n",
      "1. Deep Rock Galactic\n",
      "2. Halo Infinite\n",
      "3. BattleBit Remastered\n",
      "4. Dota 2\n",
      "5. Tom Clancy's Rainbow Six Siege\n",
      "6. Rust\n"
     ]
    }
   ],
   "source": [
    "#engine 3.1 (using IVFPQ)\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Load all necessary components ---\n",
    "df_games = pd.read_csv(\"df_games.csv\")  # Or your full cleaned dataset CSV\n",
    "vectors = np.load(\"final_production_vectors.npy\")  # Load the improved hybrid vectors\n",
    "\n",
    "# Ensure vectors match the dimensionality of the Faiss index\n",
    "if vectors.shape[1] < 304:\n",
    "    padding_size = 304 - vectors.shape[1]\n",
    "    print(f\"Padding vectors: Adding {padding_size} dimensions to match Faiss index dimensionality.\")\n",
    "    vectors = np.hstack([vectors, np.zeros((vectors.shape[0], padding_size), dtype='float32')])\n",
    "elif vectors.shape[1] > 304:\n",
    "    print(f\"Error: Vectors have more dimensions ({vectors.shape[1]}) than the Faiss index ({304}).\")\n",
    "    exit()\n",
    "\n",
    "vectors = vectors.astype('float32')  # Convert to float32 if necessary\n",
    "print(\"Adjusted shape of vectors:\", vectors.shape)\n",
    "\n",
    "# Load the pre-built Faiss index\n",
    "try:\n",
    "    index = faiss.read_index(\"production_games.index\")  # Load the saved production index\n",
    "    print(\"Successfully loaded production index.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: production_games.index not found. Please ensure the index file exists.\")\n",
    "    exit()\n",
    "\n",
    "# Verify the dimensions of the vectors and the Faiss index\n",
    "print(f\"Shape of vectors: {vectors.shape}\")\n",
    "print(f\"Faiss index dimensionality: {index.d}\")\n",
    "\n",
    "# Ensure the Faiss index dimensionality matches the vectors\n",
    "if vectors.shape[1] != index.d:\n",
    "    print(f\"Error: Dimensionality mismatch. Vectors have {vectors.shape[1]} dimensions, but the Faiss index expects {index.d}.\")\n",
    "    exit()\n",
    "\n",
    "title_to_index = pd.Series(df_games.index, index=df_games['name'])\n",
    "\n",
    "def get_profile_recommendations(game_titles, ratings, k=6): # Added 'ratings' parameter\n",
    "    \"\"\"\n",
    "    Finds and prints recommendations based on a weighted average profile of input games.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the number of games and ratings match\n",
    "        if len(game_titles) != len(ratings):\n",
    "            print(\"Error: The number of games and ratings must be the same.\")\n",
    "            return\n",
    "\n",
    "        # 1. Check if all titles exist in the dataset\n",
    "        missing_titles = [title for title in game_titles if title not in title_to_index.index]\n",
    "        if missing_titles:\n",
    "            print(f\"Error: The following games were not found in the dataset: {', '.join(missing_titles)}\")\n",
    "            return\n",
    "        \n",
    "        # 2. Get the vectors for all input games\n",
    "        input_vectors = []\n",
    "        for title in game_titles:\n",
    "            if title in title_to_index:\n",
    "                input_vectors.append(vectors[title_to_index[title]])\n",
    "            else:\n",
    "                print(f\"Warning: '{title}' not found. Skipping.\")\n",
    "\n",
    "        if not input_vectors:\n",
    "            print(\"Error: None of the input games were found.\")\n",
    "            return\n",
    "\n",
    "        # 3. Calculate the WEIGHTED average vector to create the \"taste profile\"\n",
    "        query_vector = np.average(input_vectors, axis=0, weights=ratings).reshape(1, -1).astype('float32')\n",
    "\n",
    "        # Ensure the query vector is contiguous in memory\n",
    "        query_vector = np.ascontiguousarray(query_vector, dtype='float32')\n",
    "\n",
    "        # Verify the dimensions of the query vector\n",
    "        print(f\"Shape of query vector: {query_vector.shape}\")\n",
    "\n",
    "        # Set nprobe for the loaded index\n",
    "        index.nprobe = 10 \n",
    "        \n",
    "        # 4. Search the Faiss index\n",
    "        distances, indices = index.search(query_vector, k)\n",
    "        \n",
    "        print(f\"--- Recommendations for a fan of {', '.join(game_titles)} ---\")\n",
    "        \n",
    "        # 5. Print the results, filtering out the input games\n",
    "        recs = []\n",
    "        for i in range(k):\n",
    "            rec_title = df_games.iloc[indices[0][i]]['name']\n",
    "            if rec_title not in game_titles:\n",
    "                recs.append(rec_title)\n",
    "        \n",
    "        for i, rec in enumerate(recs):\n",
    "            print(f\"{i+1}. {rec}\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Game {e} not found in the dataset.\")\n",
    "\n",
    "# --- Now, test with both games! ---\n",
    "test_games = [\"Counter Strike 2\", \"Grand Theft Auto V\", \"Red Dead Redemption 2\"]\n",
    "# Add a list of ratings (out of 10) to correspond to the games\n",
    "test_ratings = [10, 10, 5]\n",
    "# Call the function with the new ratings parameter\n",
    "get_profile_recommendations(test_games, test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2843e1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of vectors: (88886, 300)\n",
      "Padding vectors: Adding 4 dimensions to make 304 divisible by 8.\n",
      "Adjusted shape of vectors: (88886, 304)\n",
      "Training the production index...\n",
      "Adding vectors to the index...\n",
      "Saving index to 'production_games.index'...\n",
      "Production index created successfully.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Load the final production vectors\n",
    "vectors = np.load(\"final_production_vectors.npy\")  # Ensure this file exists and contains the correct vectors\n",
    "vectors = vectors.astype('float32')  # Convert to float32 if necessary\n",
    "print(\"Original shape of vectors:\", vectors.shape)\n",
    "\n",
    "# Define parameters\n",
    "d_original = vectors.shape[1]  # Current dimensionality\n",
    "m = 8  # Number of sub-quantizers\n",
    "\n",
    "# Check if the dimensionality is divisible by m\n",
    "if d_original % m != 0:\n",
    "    # Calculate the new dimensionality\n",
    "    d_new = (d_original // m + 1) * m\n",
    "    padding_size = d_new - d_original\n",
    "    print(f\"Padding vectors: Adding {padding_size} dimensions to make {d_new} divisible by {m}.\")\n",
    "\n",
    "    # Add padding\n",
    "    padding = np.zeros((vectors.shape[0], padding_size), dtype='float32')\n",
    "    vectors = np.hstack([vectors, padding])\n",
    "\n",
    "print(\"Adjusted shape of vectors:\", vectors.shape)\n",
    "\n",
    "# Define dimensions and parameters\n",
    "d = vectors.shape[1]  # Updated number of dimensions\n",
    "nlist = 1024          # Number of clusters\n",
    "nbits = 8             # Number of bits per sub-quantizer\n",
    "\n",
    "# Build the index structure\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, nbits)\n",
    "\n",
    "# Train the index\n",
    "print(\"Training the production index...\")\n",
    "index.train(vectors)\n",
    "\n",
    "# Add vectors to the index\n",
    "print(\"Adding vectors to the index...\")\n",
    "index.add(vectors)\n",
    "\n",
    "# Save the index\n",
    "print(\"Saving index to 'production_games.index'...\")\n",
    "faiss.write_index(index, \"production_games.index\")\n",
    "\n",
    "print(\"Production index created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb4f41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of vectors: (88886, 300)\n",
      "Shape of query vector: (1, 300)\n",
      "--- Recommendations for a fan of EA SPORTS FC 25, Grand Theft Auto V, Red Dead Redemption 2 ---\n",
      "1. Cyberpunk 2077\n",
      "2. Apex Legends\n",
      "3. Baldur's Gate 3\n",
      "4. 7 Days to Die\n",
      "5. Sons Of The Forest\n"
     ]
    }
   ],
   "source": [
    "#engine 3 (not to be touched)\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Load all necessary components ---\n",
    "df_games = pd.read_csv(\"df_games.csv\")  # Or your full cleaned dataset CSV\n",
    "vectors = np.load(\"final_production_vectors.npy\")  # Load the improved hybrid vectors\n",
    "\n",
    "# Verify the dimensions of the vectors\n",
    "print(f\"Shape of vectors: {vectors.shape}\")\n",
    "\n",
    "# Rebuild the Faiss index with the correct dimensions\n",
    "d = vectors.shape[1]  # Number of dimensions\n",
    "index = faiss.IndexFlatL2(d)  # L2 distance metric\n",
    "index.add(vectors)  # Add the vectors to the index\n",
    "\n",
    "title_to_index = pd.Series(df_games.index, index=df_games['name'])\n",
    "\n",
    "def get_profile_recommendations(game_titles, ratings, k=6): # Added 'ratings' parameter\n",
    "    \"\"\"\n",
    "    Finds and prints recommendations based on a weighted average profile of input games.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the number of games and ratings match\n",
    "        if len(game_titles) != len(ratings):\n",
    "            print(\"Error: The number of games and ratings must be the same.\")\n",
    "            return\n",
    "\n",
    "        # 1. Check if all titles exist in the dataset\n",
    "        missing_titles = [title for title in game_titles if title not in title_to_index.index]\n",
    "        if missing_titles:\n",
    "            print(f\"Error: The following games were not found in the dataset: {', '.join(missing_titles)}\")\n",
    "            return\n",
    "        \n",
    "        # 2. Get the vectors for all input games\n",
    "        input_vectors = [vectors[title_to_index[title]] for title in game_titles]\n",
    "        \n",
    "        # 3. Calculate the WEIGHTED average vector to create the \"taste profile\"\n",
    "        query_vector = np.average(input_vectors, axis=0, weights=ratings).reshape(1, -1).astype('float32')\n",
    "        \n",
    "        # Verify the dimensions of the query vector\n",
    "        print(f\"Shape of query vector: {query_vector.shape}\")\n",
    "\n",
    "        # New line: Increase the search accuracy\n",
    "        index.nprobe = 10 \n",
    "        \n",
    "        # 4. Search the Faiss index\n",
    "        distances, indices = index.search(query_vector, k)\n",
    "        \n",
    "        print(f\"--- Recommendations for a fan of {', '.join(game_titles)} ---\")\n",
    "        \n",
    "        # 5. Print the results, filtering out the input games\n",
    "        recs = []\n",
    "        for i in range(k):\n",
    "            rec_title = df_games.iloc[indices[0][i]]['name']\n",
    "            if rec_title not in game_titles:\n",
    "                recs.append(rec_title)\n",
    "        \n",
    "        for i, rec in enumerate(recs):\n",
    "            print(f\"{i+1}. {rec}\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Game {e} not found in the dataset.\")\n",
    "\n",
    "    \n",
    "\n",
    "# --- Now, test with both games! ---\n",
    "test_games = [\"EA SPORTS FC 25\", \"Grand Theft Auto V\", \"Red Dead Redemption 2\"]\n",
    "# Add a list of ratings (out of 10) to correspond to the games\n",
    "test_ratings = [1, 2, 10]\n",
    "# Call the function with the new ratings parameter\n",
    "get_profile_recommendations(test_games, test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad65ec23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of query vector: (1, 300)\n",
      "--- Recommendations for a fan of Marvel's Spider Man 2, Grand Theft Auto V, Red Dead Redemption 2 ---\n",
      "1. Mafia II Classic\n",
      "2. V Rising\n",
      "3. Ready or Not\n",
      "4. Path of Exile 2\n",
      "5. Kingdom Come Deliverance II\n"
     ]
    }
   ],
   "source": [
    "# --- Now, test with both games! ---\n",
    "test_games = [\"Marvel's Spider Man 2\", \"Grand Theft Auto V\", \"Red Dead Redemption 2\"]\n",
    "# Add a list of ratings (out of 10) to correspond to the games\n",
    "test_ratings = [10, 10, 10]\n",
    "# Call the function with the new ratings parameter\n",
    "get_profile_recommendations(test_games, test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42cfaec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of query vector: (1, 300)\n",
      "--- Recommendations for a fan of Cyberpunk 2077, Apex Legends, Sons Of The Forest, EA SPORTS FC 25, Grand Theft Auto V, Red Dead Redemption 2 ---\n",
      "1. My Summer Car\n",
      "2. Call of Duty\n",
      "3. 7 Days to Die\n",
      "4. Marvel Rivals\n"
     ]
    }
   ],
   "source": [
    "# --- Now, test with both games! ---\n",
    "test_games = [\"Cyberpunk 2077\", \"Apex Legends\", \"Sons Of The Forest\", \"EA SPORTS FC 25\", \"Grand Theft Auto V\", \"Red Dead Redemption 2\"]\n",
    "# Add a list of ratings (out of 10) to correspond to the games\n",
    "test_ratings = [1, 1, 2, 2, 8, 8]\n",
    "# Call the function with the new ratings parameter\n",
    "get_profile_recommendations(test_games, test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "179a94e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of vectors: (88886, 300)\n",
      "\n",
      "Saving index to 'games_index.index'...\n",
      "Index saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Load all necessary components ---\n",
    "df_games = pd.read_csv(\"df_games.csv\")  # Or your full cleaned dataset CSV\n",
    "vectors = np.load(\"final_production_vectors.npy\")  # Load the improved hybrid vectors\n",
    "\n",
    "# Verify the dimensions of the vectors\n",
    "print(f\"Shape of vectors: {vectors.shape}\")\n",
    "\n",
    "# Rebuild the Faiss index with the correct dimensions\n",
    "d = vectors.shape[1]  # Number of dimensions\n",
    "index = faiss.IndexFlatL2(d)  # L2 distance metric\n",
    "index.add(vectors)  # Add the vectors to the index\n",
    "\n",
    "title_to_index = pd.Series(df_games.index, index=df_games['name'])\n",
    "\n",
    "def get_profile_recommendations(game_titles, ratings, k=6):\n",
    "    \"\"\"\n",
    "    Finds and prints recommendations based on a weighted average profile of input games.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the number of games and ratings match\n",
    "        if len(game_titles) != len(ratings):\n",
    "            print(\"Error: The number of games and ratings must be the same.\")\n",
    "            return []\n",
    "\n",
    "        # 1. Check if all titles exist in the dataset\n",
    "        missing_titles = [title for title in game_titles if title not in title_to_index.index]\n",
    "        if missing_titles:\n",
    "            print(f\"Error: The following games were not found in the dataset: {', '.join(missing_titles)}\")\n",
    "            return []\n",
    "\n",
    "        # 2. Get the vectors for all input games\n",
    "        input_vectors = [vectors[title_to_index[title]] for title in game_titles]\n",
    "\n",
    "        # 3. Calculate the WEIGHTED average vector to create the \"taste profile\"\n",
    "        query_vector = np.average(input_vectors, axis=0, weights=ratings).reshape(1, -1).astype('float32')\n",
    "\n",
    "        # Verify the dimensions of the query vector\n",
    "        print(f\"Shape of query vector: {query_vector.shape}\")\n",
    "\n",
    "        # Set nprobe for the loaded index\n",
    "        index.nprobe = 10 \n",
    "        \n",
    "        # 4. Search the Faiss index\n",
    "        distances, indices = index.search(query_vector, k)\n",
    "\n",
    "        print(f\"--- Recommendations for a fan of {', '.join(game_titles)} ---\")\n",
    "        \n",
    "        # 5. Collect the results, filtering out the input games\n",
    "        recs = []\n",
    "        for i in range(k):\n",
    "            rec_title = df_games.iloc[indices[0][i]]['name']\n",
    "            if rec_title not in game_titles:\n",
    "                recs.append(rec_title)\n",
    "\n",
    "        for i, rec in enumerate(recs):\n",
    "            print(f\"{i+1}. {rec}\")\n",
    "\n",
    "        return recs\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Game {e} not found in the dataset.\")\n",
    "        return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- Save the index to a file ---\n",
    "print(\"\\nSaving index to 'games_index.index'...\")\n",
    "faiss.write_index(index, \"games_index.index\")\n",
    "print(\"Index saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e223257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>about_the_game</th>\n",
       "      <th>short_description</th>\n",
       "      <th>windows</th>\n",
       "      <th>mac</th>\n",
       "      <th>linux</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>publishers</th>\n",
       "      <th>...</th>\n",
       "      <th>ps5</th>\n",
       "      <th>xbox</th>\n",
       "      <th>tags_cleaned</th>\n",
       "      <th>combined</th>\n",
       "      <th>game_age</th>\n",
       "      <th>reviews_per_year</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>keyword_soup</th>\n",
       "      <th>publisher_cleaned</th>\n",
       "      <th>combined_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1144200</td>\n",
       "      <td>Ready or Not</td>\n",
       "      <td>2023-12-13</td>\n",
       "      <td>Be sure to join the Ready or Not Discord serve...</td>\n",
       "      <td>Ready or Not is an intense, tactical, first-pe...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>176271</td>\n",
       "      <td>['VOID Interactive']</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Tactical Tactical Tactical Tactical Tactical T...</td>\n",
       "      <td>['Single-player', 'Multi-player', 'Co-op', 'On...</td>\n",
       "      <td>2</td>\n",
       "      <td>58920</td>\n",
       "      <td>0.888533</td>\n",
       "      <td>Tactical Tactical Tactical Tactical Tactical T...</td>\n",
       "      <td>['voidinteractive']</td>\n",
       "      <td>Ready or Not is an intense, tactical, first-pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      appid          name release_date  \\\n",
       "89  1144200  Ready or Not   2023-12-13   \n",
       "\n",
       "                                       about_the_game  \\\n",
       "89  Be sure to join the Ready or Not Discord serve...   \n",
       "\n",
       "                                    short_description  windows    mac  linux  \\\n",
       "89  Ready or Not is an intense, tactical, first-pe...     True  False  False   \n",
       "\n",
       "    recommendations            publishers  ...    ps5   xbox  \\\n",
       "89           176271  ['VOID Interactive']  ...  False  False   \n",
       "\n",
       "                                         tags_cleaned  \\\n",
       "89  Tactical Tactical Tactical Tactical Tactical T...   \n",
       "\n",
       "                                             combined  game_age  \\\n",
       "89  ['Single-player', 'Multi-player', 'Co-op', 'On...         2   \n",
       "\n",
       "    reviews_per_year  quality_score  \\\n",
       "89             58920       0.888533   \n",
       "\n",
       "                                         keyword_soup    publisher_cleaned  \\\n",
       "89  Tactical Tactical Tactical Tactical Tactical T...  ['voidinteractive']   \n",
       "\n",
       "                                combined_descriptions  \n",
       "89  Ready or Not is an intense, tactical, first-pe...  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(df_games, 'name', \"Ready or not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbfe42a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
